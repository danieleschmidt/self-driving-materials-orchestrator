#!/usr/bin/env python3
"""
Autonomous Scaling Test - Generation 3 Implementation
Tests high-performance scaling with concurrent experiment execution.
"""

import time
import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def run_scaling_test():
    """Run comprehensive scaling test."""
    import sys
    sys.path.insert(0, 'src')
    
    from materials_orchestrator import (
        AutonomousLab,
        MaterialsObjective,
        BayesianPlanner,
        get_global_optimizer
    )
    
    print("üöÄ AUTONOMOUS SCALING TEST - GENERATION 3")
    print("=" * 60)
    
    # Initialize high-performance lab
    optimizer = get_global_optimizer()
    planner = BayesianPlanner(target_property="band_gap")
    
    lab = AutonomousLab(
        robots=["synthesis_bot_1", "synthesis_bot_2", "characterization_bot_1"],
        instruments=["xrd_1", "uv_vis_1", "pl_spectrometer_1", "sem_1"],
        planner=planner,
        enable_monitoring=True
    )
    
    # Define high-throughput objective
    objective = MaterialsObjective(
        target_property="band_gap",
        target_range=(1.2, 1.6),
        optimization_direction="target",
        material_system="perovskites"
    )
    
    # High-dimensional parameter space
    param_space = {
        "precursor_A_conc": (0.1, 2.0),
        "precursor_B_conc": (0.1, 2.0), 
        "precursor_C_conc": (0.05, 1.0),  # Additional complexity
        "temperature": (100, 300),
        "reaction_time": (1, 24),
        "pH": (3, 11),
        "solvent_ratio": (0, 1),
        "annealing_temp": (200, 400),  # Additional parameter
        "annealing_time": (0.5, 12),   # Additional parameter
    }
    
    print(f"üéØ Objective: Optimize {objective.target_property}")
    print(f"üìä Parameter space: {len(param_space)} dimensions")
    print(f"ü§ñ Laboratory: {len(lab.robots)} robots, {len(lab.instruments)} instruments")
    print()
    
    # High-throughput campaign test
    print("‚ö° HIGH-THROUGHPUT SCALING TEST")
    print("-" * 40)
    
    start_time = time.time()
    
    # Run intensive campaign
    campaign = lab.run_campaign(
        objective=objective,
        param_space=param_space,
        initial_samples=25,        # More initial exploration
        max_experiments=150,       # Higher experiment count
        concurrent_experiments=8,  # High concurrency
        convergence_patience=30,
        stop_on_target=True
    )
    
    end_time = time.time()
    duration = end_time - start_time
    throughput = campaign.total_experiments / (duration / 3600)  # experiments/hour
    
    print("\nüèÜ SCALING RESULTS")
    print("=" * 50)
    print(f"Total experiments: {campaign.total_experiments}")
    print(f"Successful experiments: {campaign.successful_experiments}")
    print(f"Success rate: {campaign.success_rate:.1%}")
    print(f"Campaign duration: {duration:.1f} seconds")
    print(f"Throughput: {throughput:.1f} experiments/hour")
    print(f"Average time per experiment: {duration/campaign.total_experiments:.2f} seconds")
    
    # Performance metrics
    if hasattr(optimizer, 'metrics'):
        metrics = optimizer.metrics
        print(f"\nüìä PERFORMANCE METRICS")
        print("-" * 25)
        print(f"Max concurrent experiments: {getattr(metrics, 'max_concurrent_experiments', 'N/A')}")
        print(f"Cache hit rate: {getattr(metrics, 'cache_hit_rate', 'N/A'):.1%}")
        print(f"Auto-scale events: {getattr(metrics, 'auto_scale_events', 'N/A')}")
    
    # Best material results
    if campaign.best_material:
        print(f"\nü•á BEST MATERIAL FOUND")
        print("-" * 25)
        best_props = campaign.best_properties
        print(f"Band gap: {best_props.get('band_gap', 'N/A'):.3f} eV")
        print(f"Efficiency: {best_props.get('efficiency', 'N/A'):.1f}%")
        print(f"Stability: {best_props.get('stability', 'N/A'):.3f}")
        
        print(f"\nüî¨ OPTIMAL PARAMETERS")
        print("-" * 20)
        for param, value in campaign.best_material['parameters'].items():
            if isinstance(value, (int, float)):
                print(f"   {param}: {value:.3f}")
            else:
                print(f"   {param}: {value}")
    
    # Acceleration analysis
    traditional_estimate = 500  # Traditional experimental estimate
    acceleration = traditional_estimate / campaign.total_experiments
    print(f"\n‚ö° ACCELERATION ANALYSIS")
    print("-" * 25)
    print(f"Experiments to target: {campaign.total_experiments}")
    print(f"Traditional estimate: {traditional_estimate}")
    print(f"Acceleration factor: {acceleration:.1f}x faster")
    print(f"Time saved: {traditional_estimate - campaign.total_experiments} experiments")
    
    # Scaling performance rating
    if throughput > 1000:
        scale_rating = "üåü ULTRA-HIGH PERFORMANCE"
    elif throughput > 500:
        scale_rating = "‚≠ê HIGH PERFORMANCE"  
    elif throughput > 100:
        scale_rating = "‚ú® GOOD PERFORMANCE"
    else:
        scale_rating = "üìà BASELINE PERFORMANCE"
    
    print(f"\nüéØ SCALING PERFORMANCE: {scale_rating}")
    print(f"Throughput achieved: {throughput:.0f} experiments/hour")
    
    return campaign, throughput


def run_concurrent_campaigns_test():
    """Test multiple concurrent campaigns."""
    import sys
    sys.path.insert(0, 'src')
    
    from materials_orchestrator import (
        AutonomousLab, 
        MaterialsObjective,
        BayesianPlanner
    )
    
    print("\nüî• CONCURRENT CAMPAIGNS TEST")
    print("=" * 40)
    
    def run_single_campaign(campaign_id):
        """Run a single campaign for concurrent testing."""
        planner = BayesianPlanner(target_property="band_gap")
        lab = AutonomousLab(
            robots=[f"bot_{campaign_id}_1", f"bot_{campaign_id}_2"],
            instruments=[f"xrd_{campaign_id}", f"uv_vis_{campaign_id}"],
            planner=planner
        )
        
        objective = MaterialsObjective(
            target_property="band_gap",
            target_range=(1.2, 1.6),
            material_system=f"campaign_{campaign_id}"
        )
        
        param_space = {
            "precursor_A_conc": (0.1, 2.0),
            "precursor_B_conc": (0.1, 2.0),
            "temperature": (100, 300),
            "reaction_time": (1, 24)
        }
        
        start_time = time.time()
        campaign = lab.run_campaign(
            objective=objective,
            param_space=param_space,
            initial_samples=10,
            max_experiments=50,
            concurrent_experiments=4
        )
        duration = time.time() - start_time
        
        return {
            'campaign_id': campaign_id,
            'experiments': campaign.total_experiments,
            'success_rate': campaign.success_rate,
            'duration': duration,
            'throughput': campaign.total_experiments / (duration / 3600)
        }
    
    # Run multiple campaigns concurrently
    campaign_count = 4
    
    with ThreadPoolExecutor(max_workers=campaign_count) as executor:
        concurrent_start = time.time()
        futures = [
            executor.submit(run_single_campaign, i) 
            for i in range(campaign_count)
        ]
        
        results = [future.result() for future in futures]
        concurrent_duration = time.time() - concurrent_start
    
    # Analyze concurrent performance
    total_experiments = sum(r['experiments'] for r in results)
    avg_success_rate = sum(r['success_rate'] for r in results) / len(results)
    total_throughput = total_experiments / (concurrent_duration / 3600)
    
    print(f"Concurrent campaigns: {campaign_count}")
    print(f"Total experiments: {total_experiments}")
    print(f"Average success rate: {avg_success_rate:.1%}")
    print(f"Total duration: {concurrent_duration:.1f} seconds") 
    print(f"Combined throughput: {total_throughput:.0f} experiments/hour")
    
    for result in results:
        print(f"  Campaign {result['campaign_id']}: "
              f"{result['experiments']} exp, "
              f"{result['success_rate']:.1%} success, "
              f"{result['throughput']:.0f}/hr")
    
    return results, total_throughput


if __name__ == "__main__":
    try:
        # Test 1: High-throughput single campaign
        campaign, throughput = run_scaling_test()
        
        # Test 2: Concurrent campaigns
        concurrent_results, concurrent_throughput = run_concurrent_campaigns_test()
        
        print("\n" + "="*60)
        print("üéä AUTONOMOUS SCALING TEST COMPLETE")
        print("="*60)
        print(f"‚úÖ Single campaign throughput: {throughput:.0f} experiments/hour")
        print(f"‚úÖ Concurrent throughput: {concurrent_throughput:.0f} experiments/hour")
        print(f"‚úÖ Scaling validated: Generation 3 objectives achieved")
        
        # Overall performance assessment
        if throughput > 500 and concurrent_throughput > 1000:
            print(f"üèÜ ULTRA-HIGH PERFORMANCE SCALING ACHIEVED")
        elif throughput > 200 and concurrent_throughput > 500:
            print(f"‚≠ê HIGH PERFORMANCE SCALING ACHIEVED")
        else:
            print(f"üìà BASELINE SCALING ACHIEVED")
        
    except Exception as e:
        logger.error(f"Scaling test failed: {e}")
        raise