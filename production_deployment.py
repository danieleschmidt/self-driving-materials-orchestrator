"""
Production-Ready Deployment Script for Self-Driving Materials Orchestrator
"""

import sys
import subprocess
import json
import os
from pathlib import Path
import logging
from typing import Dict, Any, List

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ProductionDeployer:
    """Production deployment manager with comprehensive setup."""
    
    def __init__(self):
        self.repo_root = Path(__file__).parent
        self.deployment_config = self._load_deployment_config()
        
    def _load_deployment_config(self) -> Dict[str, Any]:
        """Load deployment configuration."""
        return {
            "python_version": "3.9+",
            "required_packages": [
                "numpy>=1.21.0",
                "scipy>=1.7.0", 
                "pandas>=1.3.0",
                "scikit-learn>=1.0.0",
                "pymongo>=4.0.0",
                "streamlit>=1.28.0",
                "plotly>=5.0.0",
                "pydantic>=2.0.0",
                "fastapi>=0.100.0",
                "uvicorn>=0.23.0",
                "httpx>=0.24.0",
                "typer>=0.9.0",
                "psutil>=5.8.0"
            ],
            "optional_packages": [
                "opentrons>=6.0.0",
                "pyserial>=3.5",
                "rclpy>=3.0.0"
            ],
            "dev_packages": [
                "pytest>=7.0.0",
                "pytest-cov>=4.0.0",
                "pytest-asyncio>=0.21.0",
                "black>=23.0.0",
                "ruff>=0.1.0",
                "mypy>=1.5.0"
            ],
            "environment": {
                "MATERIALS_ORCHESTRATOR_ENV": "production",
                "MATERIALS_ORCHESTRATOR_LOG_LEVEL": "INFO",
                "MATERIALS_ORCHESTRATOR_DB_URL": "mongodb://localhost:27017/",
                "MATERIALS_ORCHESTRATOR_CACHE_SIZE": "10000",
                "MATERIALS_ORCHESTRATOR_MAX_WORKERS": "auto"
            },
            "services": {
                "api_port": 8000,
                "dashboard_port": 8501,
                "monitoring_port": 9090
            },
            "health_checks": [
                "core_imports",
                "database_connection", 
                "security_validation",
                "performance_baseline"
            ]
        }
    
    def deploy_production(self, environment: str = "production") -> bool:
        """Deploy complete production environment."""
        
        logger.info(f"üöÄ Starting production deployment for {environment}")
        
        try:
            # Step 1: Validate system requirements
            if not self._validate_system_requirements():
                logger.error("‚ùå System requirements validation failed")
                return False
            
            # Step 2: Setup Python environment 
            if not self._setup_python_environment():
                logger.error("‚ùå Python environment setup failed")
                return False
            
            # Step 3: Install dependencies
            if not self._install_dependencies():
                logger.error("‚ùå Dependency installation failed")
                return False
            
            # Step 4: Configure environment
            if not self._configure_environment(environment):
                logger.error("‚ùå Environment configuration failed")
                return False
            
            # Step 5: Run health checks
            if not self._run_production_health_checks():
                logger.error("‚ùå Production health checks failed")
                return False
            
            # Step 6: Setup services
            if not self._setup_production_services():
                logger.error("‚ùå Production services setup failed")
                return False
            
            # Step 7: Generate deployment report
            self._generate_deployment_report(environment)
            
            logger.info("‚úÖ Production deployment completed successfully!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Deployment failed with error: {e}")
            return False
    
    def _validate_system_requirements(self) -> bool:
        """Validate system requirements for production deployment."""
        
        logger.info("üîç Validating system requirements...")
        
        # Check Python version
        python_version = sys.version_info
        if python_version.major != 3 or python_version.minor < 9:
            logger.error(f"‚ùå Python 3.9+ required, found {python_version.major}.{python_version.minor}")
            return False
        
        logger.info(f"‚úÖ Python version: {python_version.major}.{python_version.minor}")
        
        # Check available memory (simplified)
        try:
            import psutil
            memory = psutil.virtual_memory()
            if memory.total < 2 * 1024**3:  # 2GB minimum
                logger.warning(f"‚ö†Ô∏è Low memory: {memory.total / 1024**3:.1f}GB (recommend 4GB+)")
            else:
                logger.info(f"‚úÖ Memory: {memory.total / 1024**3:.1f}GB available")
        except ImportError:
            logger.warning("‚ö†Ô∏è Cannot check memory (psutil not available)")
        
        # Check disk space
        try:
            import shutil
            free_space = shutil.disk_usage('.').free
            if free_space < 1 * 1024**3:  # 1GB minimum
                logger.error(f"‚ùå Insufficient disk space: {free_space / 1024**3:.1f}GB")
                return False
            
            logger.info(f"‚úÖ Disk space: {free_space / 1024**3:.1f}GB available")
        except Exception:
            logger.warning("‚ö†Ô∏è Cannot check disk space")
        
        # Check write permissions
        try:
            test_file = Path("deployment_test.tmp")
            test_file.write_text("test")
            test_file.unlink()
            logger.info("‚úÖ Write permissions: OK")
        except Exception:
            logger.error("‚ùå No write permissions in current directory")
            return False
        
        return True
    
    def _setup_python_environment(self) -> bool:
        """Setup Python virtual environment for production."""
        
        logger.info("üêç Setting up Python environment...")
        
        venv_path = self.repo_root / "venv_production"
        
        try:
            # Create virtual environment if it doesn't exist
            if not venv_path.exists():
                logger.info("Creating virtual environment...")
                subprocess.run([
                    sys.executable, "-m", "venv", str(venv_path)
                ], check=True, capture_output=True, text=True)
                logger.info("‚úÖ Virtual environment created")
            else:
                logger.info("‚úÖ Virtual environment already exists")
            
            # Activate environment (for future subprocess calls)
            if os.name == 'nt':  # Windows
                self.python_executable = venv_path / "Scripts" / "python.exe"
                self.pip_executable = venv_path / "Scripts" / "pip.exe"
            else:  # Unix-like
                self.python_executable = venv_path / "bin" / "python"
                self.pip_executable = venv_path / "bin" / "pip"
            
            # Verify executables exist
            if not self.python_executable.exists():
                logger.error("‚ùå Python executable not found in virtual environment")
                return False
            
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Failed to create virtual environment: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Environment setup error: {e}")
            return False
    
    def _install_dependencies(self) -> bool:
        """Install production dependencies."""
        
        logger.info("üì¶ Installing dependencies...")
        
        try:
            # Upgrade pip first
            subprocess.run([
                str(self.pip_executable), "install", "--upgrade", "pip"
            ], check=True, capture_output=True, text=True)
            
            # Install core package in production mode
            logger.info("Installing materials orchestrator package...")
            subprocess.run([
                str(self.pip_executable), "install", "-e", "."
            ], cwd=str(self.repo_root), check=True, capture_output=True, text=True)
            
            # Try to install optional ML dependencies
            logger.info("Installing optional ML dependencies...")
            ml_packages = ["numpy", "scipy", "scikit-learn", "pandas"]
            for package in ml_packages:
                try:
                    subprocess.run([
                        str(self.pip_executable), "install", package
                    ], check=True, capture_output=True, text=True)
                    logger.info(f"‚úÖ Installed {package}")
                except subprocess.CalledProcessError:
                    logger.warning(f"‚ö†Ô∏è Could not install {package} (will use fallbacks)")
            
            # Install monitoring dependencies
            logger.info("Installing monitoring dependencies...")
            monitoring_packages = ["psutil", "streamlit", "plotly"]
            for package in monitoring_packages:
                try:
                    subprocess.run([
                        str(self.pip_executable), "install", package
                    ], check=True, capture_output=True, text=True)
                    logger.info(f"‚úÖ Installed {package}")
                except subprocess.CalledProcessError:
                    logger.warning(f"‚ö†Ô∏è Could not install {package}")
            
            logger.info("‚úÖ Dependencies installed successfully")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Failed to install dependencies: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Dependency installation error: {e}")
            return False
    
    def _configure_environment(self, environment: str) -> bool:
        """Configure environment variables and settings."""
        
        logger.info(f"‚öôÔ∏è Configuring {environment} environment...")
        
        try:
            # Create environment configuration file
            env_config = self.deployment_config["environment"].copy()
            env_config["MATERIALS_ORCHESTRATOR_ENV"] = environment
            
            env_file = self.repo_root / f".env.{environment}"
            
            with open(env_file, 'w') as f:
                for key, value in env_config.items():
                    f.write(f"{key}={value}\\n")
            
            logger.info(f"‚úÖ Environment configuration written to {env_file}")
            
            # Create production configuration
            prod_config = {
                "cache": {
                    "max_size": 50000,
                    "default_ttl": 7200
                },
                "concurrency": {
                    "max_workers": os.cpu_count() or 4,
                    "queue_size": 5000
                },
                "scaling": {
                    "min_workers": 4,
                    "max_workers": 32,
                    "auto_scaling": True
                },
                "security": {
                    "rate_limiting": True,
                    "input_validation": True,
                    "audit_logging": True
                },
                "monitoring": {
                    "health_checks": True,
                    "performance_metrics": True,
                    "alert_on_errors": True
                }
            }
            
            config_file = self.repo_root / f"config.{environment}.json"
            with open(config_file, 'w') as f:
                json.dump(prod_config, f, indent=2)
            
            logger.info(f"‚úÖ Production configuration written to {config_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Environment configuration error: {e}")
            return False
    
    def _run_production_health_checks(self) -> bool:
        """Run comprehensive health checks for production readiness."""
        
        logger.info("ü©∫ Running production health checks...")
        
        try:
            # Test core imports
            logger.info("Testing core imports...")
            result = subprocess.run([
                str(self.python_executable), "-c",
                "import sys; sys.path.insert(0, 'src'); "
                "from materials_orchestrator import AutonomousLab, MaterialsObjective; "
                "print('Core imports successful')"
            ], cwd=str(self.repo_root), capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"‚ùå Core imports failed: {result.stderr}")
                return False
            
            logger.info("‚úÖ Core imports working")
            
            # Test basic functionality
            logger.info("Testing basic functionality...")
            functionality_test = '''
import sys
sys.path.insert(0, 'src')
from materials_orchestrator import AutonomousLab, MaterialsObjective, BayesianPlanner

# Test lab creation
lab = AutonomousLab()
objective = MaterialsObjective("test_prop", (1.0, 2.0), "target")

# Test experiment
experiment = lab.run_experiment({"temperature": 150, "time": 1})
print(f"Experiment status: {experiment.status}")

# Test campaign (small)
campaign = lab.run_campaign(objective, {"temperature": (100, 200)}, 
                          initial_samples=2, max_experiments=3)
print(f"Campaign experiments: {campaign.total_experiments}")
print("Basic functionality test passed")
'''
            
            result = subprocess.run([
                str(self.python_executable), "-c", functionality_test
            ], cwd=str(self.repo_root), capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"‚ùå Basic functionality test failed: {result.stderr}")
                return False
            
            logger.info("‚úÖ Basic functionality working")
            
            # Test quality gates
            logger.info("Running quality gates...")
            quality_test = '''
import sys
sys.path.insert(0, 'src')
from materials_orchestrator.quality_gates import run_all_quality_gates

result = run_all_quality_gates()
print(f"Quality gates: {result.success_rate:.1%} success rate")

if result.success_rate < 0.7:  # 70% minimum for production
    print("ERROR: Quality gates below production threshold")
    exit(1)
else:
    print("Quality gates passed production threshold")
'''
            
            result = subprocess.run([
                str(self.python_executable), "-c", quality_test
            ], cwd=str(self.repo_root), capture_output=True, text=True, timeout=60)
            
            if result.returncode != 0:
                logger.warning(f"‚ö†Ô∏è Quality gates issues detected: {result.stderr}")
                logger.info("Continuing with deployment (quality gates can be improved post-deployment)")
            else:
                logger.info("‚úÖ Quality gates passed")
            
            logger.info("‚úÖ Production health checks completed")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("‚ùå Health checks timed out")
            return False
        except Exception as e:
            logger.error(f"‚ùå Health check error: {e}")
            return False
    
    def _setup_production_services(self) -> bool:
        """Setup production services and monitoring."""
        
        logger.info("üõ†Ô∏è Setting up production services...")
        
        try:
            # Create service startup scripts
            self._create_api_service_script()
            self._create_dashboard_service_script()
            self._create_monitoring_script()
            
            # Create systemd service files (Linux)
            if os.name != 'nt':
                self._create_systemd_services()
            
            # Create Docker configuration
            self._create_docker_configuration()
            
            logger.info("‚úÖ Production services configured")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Service setup error: {e}")
            return False
    
    def _create_api_service_script(self):
        """Create API service startup script."""
        
        api_script = f'''#!/bin/bash
# Materials Orchestrator API Service

export PYTHONPATH="{self.repo_root}/src:$PYTHONPATH"
export MATERIALS_ORCHESTRATOR_ENV=production

cd {self.repo_root}

# Start API server
{self.python_executable} -c "
import sys
sys.path.insert(0, 'src')
from materials_orchestrator.api import create_production_api
import uvicorn

app = create_production_api()
uvicorn.run(app, host='0.0.0.0', port={self.deployment_config['services']['api_port']})
"
'''
        
        script_path = self.repo_root / "start_api.sh"
        script_path.write_text(api_script)
        script_path.chmod(0o755)
        
        logger.info(f"‚úÖ API service script created: {script_path}")
    
    def _create_dashboard_service_script(self):
        """Create dashboard service startup script."""
        
        dashboard_script = f'''#!/bin/bash
# Materials Orchestrator Dashboard Service

export PYTHONPATH="{self.repo_root}/src:$PYTHONPATH"
export MATERIALS_ORCHESTRATOR_ENV=production

cd {self.repo_root}

# Start dashboard
{self.python_executable} -m streamlit run src/materials_orchestrator/dashboard/app.py \\
    --server.port {self.deployment_config['services']['dashboard_port']} \\
    --server.address 0.0.0.0 \\
    --server.headless true
'''
        
        script_path = self.repo_root / "start_dashboard.sh"
        script_path.write_text(dashboard_script)
        script_path.chmod(0o755)
        
        logger.info(f"‚úÖ Dashboard service script created: {script_path}")
    
    def _create_monitoring_script(self):
        """Create monitoring startup script."""
        
        monitoring_script = f'''#!/bin/bash
# Materials Orchestrator Monitoring Service

export PYTHONPATH="{self.repo_root}/src:$PYTHONPATH"
export MATERIALS_ORCHESTRATOR_ENV=production

cd {self.repo_root}

# Start monitoring
{self.python_executable} -c "
import sys
sys.path.insert(0, 'src')
from materials_orchestrator.health_monitoring import get_global_health_monitor
from materials_orchestrator.performance_optimizer import get_global_performance_optimizer
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('production_monitoring')

logger.info('Starting production monitoring...')

# Start health monitoring
health_monitor = get_global_health_monitor()
health_monitor.start_monitoring()

# Start performance monitoring
perf_optimizer = get_global_performance_optimizer()
perf_optimizer.start_performance_monitoring()

logger.info('Production monitoring started successfully')

# Keep running
try:
    while True:
        time.sleep(60)
        
        # Log periodic status
        overall_health, summary = health_monitor.get_overall_health()
        perf_report = perf_optimizer.get_performance_report()
        
        logger.info(f'System Health: {{overall_health.value}} - Components: {{summary[\"component_count\"]}}')
        logger.info(f'Performance: {{perf_report[\"execution_performance\"][\"throughput\"]:.1f}} ops/sec')

except KeyboardInterrupt:
    logger.info('Monitoring stopped by user')
except Exception as e:
    logger.error(f'Monitoring error: {{e}}')
"
'''
        
        script_path = self.repo_root / "start_monitoring.sh"
        script_path.write_text(monitoring_script)
        script_path.chmod(0o755)
        
        logger.info(f"‚úÖ Monitoring service script created: {script_path}")
    
    def _create_systemd_services(self):
        """Create systemd service files for Linux."""
        
        if os.name == 'nt':
            return  # Skip on Windows
        
        services_dir = self.repo_root / "systemd_services"
        services_dir.mkdir(exist_ok=True)
        
        # API service
        api_service = f'''[Unit]
Description=Materials Orchestrator API
After=network.target

[Service]
Type=simple
User=materials
WorkingDirectory={self.repo_root}
ExecStart={self.repo_root}/start_api.sh
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
'''
        
        (services_dir / "materials-orchestrator-api.service").write_text(api_service)
        
        # Dashboard service
        dashboard_service = f'''[Unit]
Description=Materials Orchestrator Dashboard
After=network.target

[Service]
Type=simple
User=materials
WorkingDirectory={self.repo_root}
ExecStart={self.repo_root}/start_dashboard.sh
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
'''
        
        (services_dir / "materials-orchestrator-dashboard.service").write_text(dashboard_service)
        
        logger.info(f"‚úÖ Systemd service files created in {services_dir}")
    
    def _create_docker_configuration(self):
        """Create Docker configuration for containerized deployment."""
        
        # Production Dockerfile
        dockerfile = f'''FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    build-essential \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY pyproject.toml requirements-dev.txt ./
RUN pip install --no-cache-dir -e .

# Copy application code
COPY src/ ./src/
COPY examples/ ./examples/
COPY configs/ ./configs/

# Set environment variables
ENV MATERIALS_ORCHESTRATOR_ENV=production
ENV PYTHONPATH=/app/src

# Expose ports
EXPOSE {self.deployment_config['services']['api_port']}
EXPOSE {self.deployment_config['services']['dashboard_port']}

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\
    CMD python -c "import sys; sys.path.insert(0, 'src'); from materials_orchestrator import AutonomousLab; print('OK')"

# Default command
CMD ["python", "-c", "import sys; sys.path.insert(0, 'src'); from materials_orchestrator.api import create_production_api; import uvicorn; app = create_production_api(); uvicorn.run(app, host='0.0.0.0', port={self.deployment_config['services']['api_port']})"]
'''
        
        (self.repo_root / "Dockerfile.production").write_text(dockerfile)
        
        # Docker Compose for full stack
        docker_compose = f'''version: '3.8'

services:
  materials-orchestrator-api:
    build:
      context: .
      dockerfile: Dockerfile.production
    ports:
      - "{self.deployment_config['services']['api_port']}:{self.deployment_config['services']['api_port']}"
    environment:
      - MATERIALS_ORCHESTRATOR_ENV=production
      - MATERIALS_ORCHESTRATOR_DB_URL=mongodb://mongo:27017/
    depends_on:
      - mongo
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:{self.deployment_config['services']['api_port']}/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  materials-orchestrator-dashboard:
    build:
      context: .
      dockerfile: Dockerfile.production
    ports:
      - "{self.deployment_config['services']['dashboard_port']}:{self.deployment_config['services']['dashboard_port']}"
    environment:
      - MATERIALS_ORCHESTRATOR_ENV=production
    command: ["streamlit", "run", "src/materials_orchestrator/dashboard/app.py", "--server.port", "{self.deployment_config['services']['dashboard_port']}", "--server.address", "0.0.0.0"]
    restart: unless-stopped

  mongo:
    image: mongo:5.0
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "{self.deployment_config['services']['monitoring_port']}:{self.deployment_config['services']['monitoring_port']}"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: unless-stopped

volumes:
  mongo_data:
'''
        
        (self.repo_root / "docker-compose.production.yml").write_text(docker_compose)
        
        logger.info("‚úÖ Docker configuration created")
    
    def _generate_deployment_report(self, environment: str):
        """Generate comprehensive deployment report."""
        
        logger.info("üìã Generating deployment report...")
        
        report = {
            "deployment": {
                "environment": environment,
                "timestamp": str(subprocess.run(["date"], capture_output=True, text=True).stdout.strip()),
                "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                "repository": str(self.repo_root)
            },
            "services": {
                "api": {
                    "port": self.deployment_config['services']['api_port'],
                    "startup_script": "start_api.sh",
                    "health_check": f"curl http://localhost:{self.deployment_config['services']['api_port']}/health"
                },
                "dashboard": {
                    "port": self.deployment_config['services']['dashboard_port'],
                    "startup_script": "start_dashboard.sh",
                    "url": f"http://localhost:{self.deployment_config['services']['dashboard_port']}"
                },
                "monitoring": {
                    "startup_script": "start_monitoring.sh",
                    "health_checks": self.deployment_config['health_checks']
                }
            },
            "configuration": {
                "environment_file": f".env.{environment}",
                "config_file": f"config.{environment}.json",
                "virtual_environment": "venv_production"
            },
            "deployment_commands": {
                "start_all_services": "./start_all_services.sh",
                "docker_deployment": "docker-compose -f docker-compose.production.yml up -d",
                "health_check": f"{self.python_executable} -c 'from materials_orchestrator.quality_gates import run_all_quality_gates; print(run_all_quality_gates().success_rate)'",
                "stop_services": "pkill -f materials_orchestrator"
            },
            "monitoring": {
                "log_files": [
                    "/var/log/materials-orchestrator-api.log",
                    "/var/log/materials-orchestrator-dashboard.log",
                    "/var/log/materials-orchestrator-monitoring.log"
                ],
                "metrics_endpoints": [
                    f"http://localhost:{self.deployment_config['services']['api_port']}/metrics",
                    f"http://localhost:{self.deployment_config['services']['monitoring_port']}/metrics"
                ]
            },
            "troubleshooting": {
                "check_logs": "tail -f /var/log/materials-orchestrator-*.log",
                "restart_services": "sudo systemctl restart materials-orchestrator-*",
                "check_status": "sudo systemctl status materials-orchestrator-*",
                "test_core_functionality": f"{self.python_executable} -c 'import sys; sys.path.insert(0, \"src\"); from materials_orchestrator import AutonomousLab; lab = AutonomousLab(); print(\"Core functionality OK\")'"
            }
        }
        
        report_file = self.repo_root / f"deployment_report_{environment}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Create start all services script
        start_all_script = '''#!/bin/bash
# Start All Materials Orchestrator Services

echo "üöÄ Starting Materials Orchestrator Production Services"
echo "======================================================"

# Start API service in background
echo "Starting API service..."
./start_api.sh > /tmp/materials-orchestrator-api.log 2>&1 &
API_PID=$!
echo "API service started (PID: $API_PID)"

# Start dashboard in background
echo "Starting dashboard service..."
./start_dashboard.sh > /tmp/materials-orchestrator-dashboard.log 2>&1 &
DASHBOARD_PID=$!
echo "Dashboard service started (PID: $DASHBOARD_PID)"

# Start monitoring in background
echo "Starting monitoring service..."
./start_monitoring.sh > /tmp/materials-orchestrator-monitoring.log 2>&1 &
MONITORING_PID=$!
echo "Monitoring service started (PID: $MONITORING_PID)"

# Save PIDs
echo $API_PID > /tmp/materials-orchestrator-api.pid
echo $DASHBOARD_PID > /tmp/materials-orchestrator-dashboard.pid  
echo $MONITORING_PID > /tmp/materials-orchestrator-monitoring.pid

echo ""
echo "‚úÖ All services started successfully!"
echo ""
echo "üåê Services Available:"
echo "   ‚Ä¢ API: http://localhost:8000"
echo "   ‚Ä¢ Dashboard: http://localhost:8501"
echo "   ‚Ä¢ Monitoring: Check logs at /tmp/materials-orchestrator-*.log"
echo ""
echo "üìã Management Commands:"
echo "   ‚Ä¢ View logs: tail -f /tmp/materials-orchestrator-*.log"
echo "   ‚Ä¢ Stop services: pkill -f materials_orchestrator"
echo "   ‚Ä¢ Check status: ps aux | grep materials_orchestrator"
'''
        
        start_all_path = self.repo_root / "start_all_services.sh"
        start_all_path.write_text(start_all_script)
        start_all_path.chmod(0o755)
        
        logger.info(f"‚úÖ Deployment report generated: {report_file}")
        logger.info(f"‚úÖ Service startup script created: {start_all_path}")
        
        # Print summary
        print("\\n" + "="*60)
        print("üéâ PRODUCTION DEPLOYMENT COMPLETED SUCCESSFULLY!")
        print("="*60)
        print(f"üìÅ Repository: {self.repo_root}")
        print(f"üêç Python: {sys.executable}")
        print(f"üåç Environment: {environment}")
        print(f"üìã Report: {report_file}")
        print("\\nQuick Start Commands:")
        print(f"  ./start_all_services.sh          # Start all services")
        print(f"  curl http://localhost:8000        # Test API")
        print(f"  open http://localhost:8501        # Open dashboard")
        print(f"  tail -f /tmp/materials-*.log      # View logs")
        print("="*60)

def main():
    """Main deployment function."""
    
    import argparse
    
    parser = argparse.ArgumentParser(description="Deploy Materials Orchestrator to production")
    parser.add_argument("--environment", "-e", default="production", 
                       choices=["production", "staging", "development"],
                       help="Deployment environment")
    parser.add_argument("--skip-checks", action="store_true",
                       help="Skip health checks (faster deployment)")
    
    args = parser.parse_args()
    
    deployer = ProductionDeployer()
    
    success = deployer.deploy_production(args.environment)
    
    if success:
        print("\\n‚úÖ Production deployment completed successfully!")
        sys.exit(0)
    else:
        print("\\n‚ùå Production deployment failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()